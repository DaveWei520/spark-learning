package willem.weiyu.bigData.structuredStreaming

import org.apache.spark.sql.SparkSession

/**
  * @author weiyu
  * @description 单词统计
  * @Date 2018/01/05 18:20
  */
object StructuredStreaming {

  def main(args: Array[String]): Unit = {
    System.setProperty("hadoop.home.dir", "D:\\hadoop-2.8.5")
    val sparkSession = SparkSession.builder().master("local").appName("StructuredStreamingDemo").getOrCreate()
    import sparkSession.implicits._

    val lines = sparkSession.readStream.format("socket").option("host","localhost").option("port",9999).load()

    val wordCount = lines.as[String].flatMap(_.split(",|，|\\s+")).groupBy("value").count()
    wordCount.createOrReplaceTempView("word_count")
    val result = sparkSession.sql("select * from word_count")
    val query = result.writeStream.outputMode("complete").format("console").start()

    query.awaitTermination()

  }
}
